* Goals

- Pretty efficient to interpret directly.
  - no SSA.
- Register machine, not stack machine
  - some research suggests that reg machines are more performant
  - but mostly because I feel like it.
- Support precise gc.
- Support closures.
  - Non-naive view of environment capture.
    (don't prevent a var from being gced due to a closure that never uses it)

* General notes

Rips off Lua pretty heavily. Register machine, each function indicates how many
registers it needs, registers implicitly on a stack, calling function shifts
register window

* Upvals & closures

Each fn has environment consisting of "upvals" (closed-over variables; name
stolen from lua, though ours are slightly different).

Closures are created by a "closure" instruction, which takes destination
register, function, and list of operands to populate environment upvals with.
Operands are:
- our registers
- our upvals

Upvals are not indirected; a closure directly contains the upvals needed. This
means they are *copied* when closed-over, so mutations to the register or upval
they came from will not propagate to them and vice versa. This is in contrast to
lua's upvals.

** Big picture re upval copying semantics

There are three possible source-language semantics for variables & closures:
- immutable variables
- mutable variables with copying semantics
- mutable variables with sharing semantics

RVM makes the first two easy to implement efficiently, but an implementation of
the last needs to do some simple analyses to generate efficient RVM code. To
allow sharing, it needs to allocate heap space (perhaps in the form of ref
cells) for the shared variables. But putting every variable on the heap is bad.
So the compiler should only put variables on the heap if they are both (a)
shared between a parent and any of its transitive child functions and (b)
mutated by one of these functions. This is a pretty simple analysis to do, and a
relatively uncommon case in practice.

In fact, there is a name for this analysis/optimization: it is called
"assignment conversion", and (unsurprisingly) appears to have originated in the
design of optimizing scheme compilers. See "ORBIT: An optimizing compiler for
scheme", David Andrew Krantz, 1988.

* Constants

General mechanism for constants is to put them into the upvals of a closure.
Since /all/ functions are closures (no special-case for toplevel funcs), this
always works. I may decide later to add more optimized ways to handle constants.

* Calling and return convention

Assume metadata-based precise gc.

Lua explicitly copies return values into place. This makes it possible for a
function to return things not in reg 0..n without explicitly moving its results
into place, probably a good thing. Might be in want of a fast path, though. (In
how many cases can we manage to get return values in registers 0..n w/o
copying?)

Lua also does tailcalls by setting up a frame as usual and then moving the frame
down. Again, allows tailcalling something without overwriting your own args /
explicitly moving args into place. Might turn out to be possible to avoid having
to do this via clever compilation, though. (Could we just fast-path tailcalls
whose args start at 0? Or memmove might already fast-path if src=dst.)

Maybe just expose a "copy register range" instruction? Probably not: it's slower
(more bytecode instructions for a common operation). Might be useful anyways,
but only add if actually needed.

- mmove a b n
  copies b..b+n to a..a+n. expects a < b.

* Labels, jumps and calls

Intra-function jumps are relative (pc offsets). Extra-function jumps/calls are
all indirect (through function pointers or "cells").

* Cells

TODO: Explain cells.

* Precise GC support

Tag bits for now.
_Try_ to make the C API generic enough to work with any.

Options:
1. tag bits. sml does this.

   pros:
   + pretty efficient, space- & time-wise

   cons:
   + not strictly portable (but damn close).
   + fucking the semantics of your language for its implementation.
     ie. "ugh 31 bit ints."

2. gc metadata: structure tags(&maps?), register&stack maps. makes function call
   interface "interesting".

   pros: the best.

   cons:
   + hardest to implement.
   + nigh-impossible to use from a dynamically-typed source language.
     consider (\x. f x)

3. large values (ugh large values). lua does this.

   pros:
   + can make doubles immediate too.

   cons:
   + memory inflation.
   + slow?

4. no immediate numbers. python does this.

   pros:
   + balls simple.

   cons:
   + slooooow (esp if you don't cache small ints)

* Instruction encoding notes

** Comparisons

This section is irrelevant for now, since we're not actually including an
integer comparison instruction yet.

Encoding comparisons is an interesting design point.

We take two operands, and each one could be register, upval, or immediate,
_except_ that we can rule out immediate/immediate comparison. This makes

    8 = 3*3 - 1

possibilities. However, encoding this in the minimum possible 3 bits is a PITA;
the natural encoding uses 4, with 2 bits each to specify the type (reg, upval,
imm) of each operand.

We can make do with only two comparison operations (eg. LEQ, EQ) if we're
willing to be constrained as to which branch goes where. Otherwise we want four
(LT, GEQ, EQ, NEQ). Taking the conditional is cheaper than not taking it, since
we just skip over next instruction without reading it. So not constraining
enables better optimization/performance-tweaking.

The best-performance option is probably an opcode for each combination of
comparison operation and operand types. At minimum there are 8 * 2 = 16
combinations, and at maximum there are 9 * 4 = 36. Writing the code for each
case manually would be insane, but some code-generation scheme could probably be
worked out.

For now, however, we take the simplest option: there is *one* comparison
instruction. It takes the two operands, along with a byte indicating (a) what
types the operands have (reg, upval, or imm) and (b) which comparison is desired
and. (a) is encoded in 4 bits (with the immediate/immediate case representable
but outlawed; this prohibition may or may not be enforced by the bytecode
interpreter) and (b) in 2 bits, so the whole thing can fit in a byte.

If we want our comparison ops to also support floating-point operands with IEEE
semantics, the story gets even more complicated. I'm not worrying about that for
now.

* Language vs. library vs. runtime

Unfortunately the internals of the VM are too tangled up with eris' semantics to
develop it as a separate library. However, eris itself should present a library
interface, a la Lua: it should be embeddable in other C apps.

However, since the plan is to write the compiler in Eris itself & bootstrap,
this means that we can't expose "compile source" functions from liberis itself,
since they're written in Eris! Instead, we expose "load this compiled code"
functionality, and a client app will need to load the byte-compiled code for the
compiler, then invoke the eris compiler through the eris interface. This is kind
of a pain in the ass, but I don't see a better way.

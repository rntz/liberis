* Goals

- Pretty efficient to interpret directly.
  - no SSA.
- Register machine, not stack machine
  - some research suggests that reg machines are more performant
  - but mostly because I feel like it.
- Support precise gc.
- Support closures.
  - Non-naive view of environment capture.
    (don't prevent a var from being gced due to a closure that never uses it)

* Tags
** Conclusion in brief
There are a lot of decisions to be made about representation of values and their
type tags. Current plan is to put the decision off and just represent values as
pointers to memory blocks with a type header. Go back and optimize later once
the system is built and working.

** Discussion in full
Current scheme: (WORDBITS-1)-bit ints have low bit high. Everything else is a
pointer to an allocated block with a header tag. This is necessary if I'm doing
modulo arithmetic on numbers, because anything less than 31-bit arithmetic is
unbearable. But if I'm doing a full numeric stack, then other options come to
mind.

The number of bits I use determines the minimum alignment of allocated objects.
2 bits = 4 bytes, which is my alignment constraint already on 32-bit systems. 3
bits = 8 bytes adds some overhead on 32-bit systems but might be worth it. 4
bits = 16 bytes is probably too much. A variable-length encoding might be
possible, but ugh what a PITA. Let k be the number of tag bits we eventually
decide to use.

We'll probably want more than 2^k datatypes, so we use 2^k-1 tags for common
types and reserve one tag for uncommon types; we determine the actual type of
such an object from its header, which is a pointer to type metadata.

Benefits of this scheme:
1. Faster type testing. It avoids a memory access, but I'm not sure /how/
   important that is. In most cases where we check something's type, we're about
   to be accessing its memory anyway, so further accesses should be cached.

   OTOH, type-testing is /really/ common. At a wild guess I'd say about once per
   two instructions.

   Exceptions to "we're about to be accessing its memory anyway":
   - nil check (but this is just a comparison anyway, since nil is static!)

   - symbol equality, which is most common/need-to-be-fast op on symbols.

   - values that can be stored entirely in a word (incl. tag):
     - fixnums (small ints)
     - builtins

   Actually, these exceptions suggests a 2-bit encoding:
   - tag for fixnum
   - tag for builtins
   - tag for symbols, incl. nil
   - tag for everything else

   Might want a tag for closures, too...

2. (DISCREDITED) Lower memory overhead (eg. conses go from 3-word to 2-word)?

   However, our GC needs to store metadata bits. A type header is the perfect
   place; even if it's a pointer, we can use the lower 2 bits to store the GC
   metadata (simple copying and mark/sweep collectors need only 1 bit).
   Moreover, a mark/sweep collector _needs_ type (or at least size) headers in
   order to scan the heap during the "sweep" phase.

3. (DISCREDITED) GC speedup, since GC can switch on 3-bit tag and special-case
   the common datatypes. However, could do this with pointer-based scheme as
   well (though as if/else chain, not switch). Is this really the time-consuming
   part of GC? Probably not.

Disbenefits of it:
1. Slight extra overhead on dealing with "uncommon" types.

2. It makes the "undefined" state of cells more interesting, and possibly less
   efficient, to encode.

3. (DISCREDITED) Need full numeric stack. 29-bit 2's complement arithmetic is
   not bearable. But I want this anyway.

*** What tags would we use if we had 8 tags?
1. Fixnum
2. Closure
3. Builtin
4. Cons
5. ? Nil
6. ? String
7. ? Symbol
8. Tagged object (? or nil if null)

Unfortunately this is a decision that would optimally be made with the aid of
hard evidence on the performance impacts, but I have no such evidence.

Candidates:
- *Nil/empty list*

  If nil is just a symbol, this is infeasible. On the other hand, could make
  symbols 3-bit tagged. Then comparing against nil is slightly more interesting.
  Could solve "compare with nil" by pre-interning nil, and having it be a
  statically known value. This seems perhaps the best option, as long as I'm
  okay with nil being a symbol.

  Alternatively, nil could have the 3-bit tag of a type that doesn't contain it,
  but whose content is a pointer (not an immediate), and be a NULL pointer. This
  puts extra overhead on the usage of that type, though. Likely types:
  - tagged object (if we're gonna have extra overhead, put it on the uncommon case)
  - symbol (is nil a symbol?)
  - cons (nil is "empty list"; punnery on use of conses for lists)

- *String*
  String manipulation is fairly common.

- *Symbol*
  How common is symbol manipulation, anyway? We don't do it when looking up
  globals. OTOH, if we use symbols for representing branches of ADTs etc, then
  checking symbol equality will be common.

- *Extnum/Boxed number*
  Not sure this is a good idea. Boxed numbers will need tags indicating their
  representation (large integer, rational, float) anyway, so why not just tagged
  object?

Non-candidates:
- *Cell*

  Loading through cells is so common that LOAD_CELL doesn't check that the thing
  it's loading through is in fact a cell; ensuring that is up to the compiler.
  So this doesn't actually need to be 3-bit tagged!

* Builtins

The original plan was to implement builtins (eg. cons, car, cdr, +, -, *, /) as
C functions. Perhaps as "special" C functions that don't get the normal
stack-based treatment, or perhaps not. But in either case, significant overhead
for calling them. Instead we could have another type, builtins, that the
compiler knows how to handle. Code involving "cons" doesn't get compiled
specially - it's still a call through a cell, so "cons" can be
overridden/redefined. But when we actually run the call instruction, it simply
notes that the "function" value is a builtin, and switches on it.

* General notes

Rips off Lua pretty heavily. Register machine, each function indicates how many
registers it needs, registers implicitly on a stack, calling function shifts
register window

* Upvals & closures

Each fn has environment consisting of "upvals" (closed-over variables; name
stolen from lua, though ours are slightly different).

Closures are created by a "closure" instruction, which takes destination
register, function, and list of operands to populate environment upvals with.
Operands are:
- our registers
- our upvals

Upvals are not indirected; a closure directly contains the upvals needed. This
means they are *copied* when closed-over, so mutations to the register or upval
they came from will not propagate to them and vice versa. This is in contrast to
lua's upvals.

** Big picture re upval copying semantics

There are three possible source-language semantics for variables & closures:
- immutable variables
- mutable variables with copying semantics
- mutable variables with sharing semantics

RVM makes the first two easy to implement efficiently, but an implementation of
the last needs to do some simple analyses to generate efficient RVM code. To
allow sharing, it needs to allocate heap space (perhaps in the form of ref
cells) for the shared variables. But putting every variable on the heap is bad.
So the compiler should only put variables on the heap if they are both (a)
shared between a parent and any of its transitive child functions and (b)
mutated by one of these functions. This is a pretty simple analysis to do, and a
relatively uncommon case in practice.

In fact, there is a name for this analysis/optimization: it is called
"assignment conversion", and (unsurprisingly) appears to have originated in the
design of optimizing scheme compilers. See "ORBIT: An optimizing compiler for
scheme", David Andrew Krantz, 1988.

* Constants

General mechanism for constants is to put them into the upvals of a closure.
Since /all/ functions are closures (no special-case for toplevel funcs), this
always works. I may decide later to add more optimized ways to handle constants.

* Calling and return convention

Assume metadata-based precise gc.

Lua explicitly copies return values into place. This makes it possible for a
function to return things not in reg 0..n without explicitly moving its results
into place, probably a good thing. Might be in want of a fast path, though. (In
how many cases can we manage to get return values in registers 0..n w/o
copying?)

Lua also does tailcalls by setting up a frame as usual and then moving the frame
down. Again, allows tailcalling something without overwriting your own args /
explicitly moving args into place. Might turn out to be possible to avoid having
to do this via clever compilation, though. (Could we just fast-path tailcalls
whose args start at 0? Or memmove might already fast-path if src=dst.)

Maybe just expose a "copy register range" instruction? Probably not: it's slower
(more bytecode instructions for a common operation). Might be useful anyways,
but only add if actually needed.

- mmove a b n
  copies b..b+n to a..a+n. expects a < b.

* Labels, jumps and calls

Intra-function jumps are relative (pc offsets). Extra-function jumps/calls are
all indirect (through function pointers or "cells").

* Cells

TODO: Explain cells.

* Precise GC support

Tag bits for now.
_Try_ to make the C API generic enough to work with any.

Options:
1. tag bits. sml does this.

   pros:
   + pretty efficient, space- & time-wise

   cons:
   + not strictly portable (but damn close).
   + fucking the semantics of your language for its implementation.
     ie. "ugh 31 bit ints."

2. gc metadata: structure tags(&maps?), register&stack maps. makes function call
   interface "interesting".

   pros: the best.

   cons:
   + hardest to implement.
   + nigh-impossible to use from a dynamically-typed source language.
     consider (\x. f x)

3. large values (ugh large values). lua does this.

   pros:
   + can make doubles immediate too.

   cons:
   + memory inflation.
   + slow?

4. no immediate numbers. python does this.

   pros:
   + balls simple.

   cons:
   + slooooow (esp if you don't cache small ints)

* Instruction encoding notes

** Comparisons

This section is irrelevant for now, since we're not actually including an
integer comparison instruction yet.

Encoding comparisons is an interesting design point.

We take two operands, and each one could be register, upval, or immediate,
_except_ that we can rule out immediate/immediate comparison. This makes

    8 = 3*3 - 1

possibilities. However, encoding this in the minimum possible 3 bits is a PITA;
the natural encoding uses 4, with 2 bits each to specify the type (reg, upval,
imm) of each operand.

We can make do with only two comparison operations (eg. LEQ, EQ) if we're
willing to be constrained as to which branch goes where. Otherwise we want four
(LT, GEQ, EQ, NEQ). Taking the conditional is cheaper than not taking it, since
we just skip over next instruction without reading it. So not constraining
enables better optimization/performance-tweaking.

The best-performance option is probably an opcode for each combination of
comparison operation and operand types. At minimum there are 8 * 2 = 16
combinations, and at maximum there are 9 * 4 = 36. Writing the code for each
case manually would be insane, but some code-generation scheme could probably be
worked out.

For now, however, we take the simplest option: there is *one* comparison
instruction. It takes the two operands, along with a byte indicating (a) what
types the operands have (reg, upval, or imm) and (b) which comparison is desired
and. (a) is encoded in 4 bits (with the immediate/immediate case representable
but outlawed; this prohibition may or may not be enforced by the bytecode
interpreter) and (b) in 2 bits, so the whole thing can fit in a byte.

If we want our comparison ops to also support floating-point operands with IEEE
semantics, the story gets even more complicated. I'm not worrying about that for
now.

* Language vs. library vs. runtime

Unfortunately the internals of the VM are too tangled up with eris' semantics to
develop it as a separate library. However, eris itself should present a library
interface, a la Lua: it should be embeddable in other C apps.

However, since the plan is to write the compiler in Eris itself & bootstrap,
this means that we can't expose "compile source" functions from liberis itself,
since they're written in Eris! Instead, we expose "load this compiled code"
functionality, and a client app will need to load the byte-compiled code for the
compiler, then invoke the eris compiler through the eris interface. This is kind
of a pain in the ass, but I don't see a better way.
